<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>preparation | On Call Life</title>
    <link>/tags/preparation/</link>
      <atom:link href="/tags/preparation/index.xml" rel="self" type="application/rss+xml" />
    <description>preparation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 05 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>preparation</title>
      <link>/tags/preparation/</link>
    </image>
    
    <item>
      <title>Distinguishing Prevention and Preparation</title>
      <link>/post/distinguishing-prevention-and-preparation/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/distinguishing-prevention-and-preparation/</guid>
      <description>&lt;p&gt;You’ve probably heard all your life the adage, attributed to Benjamin Franklin,
that “an ounce of prevention is worth a pound of cure.” The accepted meaning is
that it’s better to keep a problem from happening than to fix it after it’s
happened.&lt;/p&gt;
&lt;p&gt;In your efforts to achieve a high level of reliability for your systems and
services, you should do everything possible to prevent incidents from occurring.
However, due to the complexity of those systems, as explained above, prevention
isn’t always possible.&lt;/p&gt;
&lt;p&gt;Thus, you must take a two-pronged approach to failure: prevention on the one
hand, and when that isn’t possible, preparation to respond – quickly and
effectively. These two are interlinked.&lt;/p&gt;
&lt;p&gt;Here’s an example of why it’s essential to do both: Sometimes an organization
will deploy an automated system. It works well. In fact, it works almost too
well – because people may take for granted that it will always work. They don’t
make proper preparation for the day that it doesn’t work. When that day comes –
as it inevitably will, sooner or later – and the system fails, it fails
spectacularly, and it’s much harder for operators to understand what went wrong.&lt;/p&gt;
&lt;p&gt;The systems you work on are made up of more than the technology. In fact, you
don’t work “on” or “with” a system; you work &lt;em&gt;in&lt;/em&gt; the system. You are part of
the system. Complex systems include both technical components (hardware,
software) and human components (people – and their personalities, training, and
knowledge).&lt;/p&gt;
&lt;p&gt;How the humans respond when things go wrong is as important as preventing things
from going wrong in the first place. We learn from failure to respond faster and
better.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/defining-the-post-incident-review/&#34;&gt;Defining the Post-incident Review&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
