<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>systems | On Call Life</title>
    <link>/tags/systems/</link>
      <atom:link href="/tags/systems/index.xml" rel="self" type="application/rss+xml" />
    <description>systems</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 05 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>systems</title>
      <link>/tags/systems/</link>
    </image>
    
    <item>
      <title>Understanding How Complex Systems Fail</title>
      <link>/post/understanding-how-complex-systems-fail/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/understanding-how-complex-systems-fail/</guid>
      <description>&lt;p&gt;You must “learn to learn” from failure not in case your systems fail, but
because it’s a certainty that your systems &lt;em&gt;will&lt;/em&gt; fail.&lt;/p&gt;
&lt;p&gt;In the IT world, the majority of systems we work with today – especially in a
cloud environment – are complex. They’re composed of many interconnecting parts
that have to work together, and the behavior of the overall system comes from
the interaction of those parts, as much as from the individual parts themselves.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Reliability&lt;/em&gt; is the thread that runs throughout this learning path, but complex
systems are never one hundred percent reliable. Such systems behave in
interesting and counterintuitive ways. The complexity of these systems means
there are inevitably minor flaws within them, and it is difficult or impossible
to predict how minor flaws can join together to produce a significant incident.&lt;/p&gt;
&lt;p&gt;For a more in-depth discussion of this topic, a good resource is the paper
titled &lt;em&gt;How Complex Systems Fail&lt;/em&gt; by Dr. Richard I. Cook with the Cognitive
Technologies Laboratory at the University of Chicago. His “short treatise on the
nature of failure” explains the causative factors that are common to the
failures of complex systems of all types, in all fields.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://web.mit.edu/2.75/resources/random/How%20Complex%20Systems%20Fail.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link: How Complex Systems
Fail&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some of his key points are particularly relevant to the incident analysis and
post-incident review process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Complex systems contain changing mixtures of failure latent within them.&lt;/strong&gt;
It is impossible for your systems to run without multiple flaws being
present. The failures change constantly because of changing technology, work
organization, and efforts to eradicate failure. Your system is never
functioning perfectly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Complex systems run in degraded mode.&lt;/strong&gt; Complex systems are always running
as “broken” systems. They keep “working” in that state because they contain
many redundancies, and people can keep them functioning despite the presence
of many flaws. System operations are dynamic, with components continually
failing and being replaced.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Catastrophe is always just around the corner.&lt;/strong&gt; The complexity of these
systems means major system failures are – in the long term – unavoidable.
Complex systems always possess the potential for catastrophic failure, and
it can happen at any time. It is impossible to eliminate this potential
because it’s part of the inherent nature of the system.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;a href=&#34;/post/distinguishing-prevention-and-preparation/&#34;&gt;Distinguishing Prevention and Preparation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
