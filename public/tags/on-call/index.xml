<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>on-call | On Call Life</title>
    <link>/tags/on-call/</link>
      <atom:link href="/tags/on-call/index.xml" rel="self" type="application/rss+xml" />
    <description>on-call</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 13 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>on-call</title>
      <link>/tags/on-call/</link>
    </image>
    
    <item>
      <title>Creating an On-call Roster Using Azure Table Storage</title>
      <link>/post/creating-an-oncall-roster-using-azure-table-storage/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/creating-an-oncall-roster-using-azure-table-storage/</guid>
      <description>&lt;p&gt;On-call rosters allow teams to identify who is responsible for acknowledging and addressing incidents as they occur.&lt;/p&gt;
&lt;p&gt;They are made up of the names and contact information of everyone expected to take part in the response and remediation of service disruptions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On-call Roster&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Email&lt;/th&gt;
&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;On-call&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jason Hand&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:jason@xyz.com&#34;&gt;jason@xyz.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;API&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Chris Smith&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:chris@xyz.com&#34;&gt;chris@xyz.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;API&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Lauren Jones&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:lauren@xyz.com&#34;&gt;lauren@xyz.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mobile&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ryan Boggs&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;mailto:ryan@xyz.com&#34;&gt;ryan@xyz.com&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Database&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Depending on the make up of your teams and services, on-call rosters can remain quite simple or become extremely complex.&lt;/p&gt;
&lt;p&gt;One way of creating an on-call roster is with a basic storage table in Azure.&lt;/p&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    First, login or create a &lt;a href=&#34;https://azure.microsoft.com/?wt.mc_id=oncalllife-blog-jahand&#34;&gt;free Azure account&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Create a new resource
From the home screen in Azure, select the option to &lt;strong&gt;create a resource&lt;/strong&gt;.
&lt;img src=&#34;create-a-resource.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Search for and select &amp;ldquo;&lt;strong&gt;Storage Account&lt;/strong&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;create-storage-account.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; Select a &lt;strong&gt;subscription&lt;/strong&gt;, &lt;strong&gt;resource group&lt;/strong&gt;, etc.&lt;/p&gt;
&lt;p&gt;Choose where you want the storage account created, what name you want to give it, as well as the type of disk and access tiers and then choose &lt;strong&gt;Review &amp;amp; Create&lt;/strong&gt;, followed by &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; Go to the (&lt;strong&gt;Storage Account&lt;/strong&gt;) resource&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt; Click on the &lt;strong&gt;Tables&lt;/strong&gt; card
&lt;img src=&#34;click-on-tables-card.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.&lt;/strong&gt; Click the &lt;strong&gt;+ Table&lt;/strong&gt; option and give it a name of &lt;code&gt;oncall&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;create-on-call-table.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7.&lt;/strong&gt; Click on &lt;strong&gt;Storage Exploror&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8.&lt;/strong&gt; Click on &lt;strong&gt;Tables&lt;/strong&gt;, then &lt;strong&gt;oncall&lt;/strong&gt;, then &lt;strong&gt;+ Add&lt;/strong&gt;
&lt;img src=&#34;open-oncall-table.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9.&lt;/strong&gt; Add &lt;strong&gt;entity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;PartitionKey&lt;/strong&gt; field will remain the same. Add new properties for &lt;strong&gt;name&lt;/strong&gt;, &lt;strong&gt;email&lt;/strong&gt;, &lt;strong&gt;service&lt;/strong&gt;, and &lt;strong&gt;oncall&lt;/strong&gt;. All properties should be set to a &lt;em&gt;string&lt;/em&gt; type, except for &lt;strong&gt;oncall&lt;/strong&gt;. It is a boolean. Once all fields have been added, press &lt;strong&gt;Insert&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;add-table-entity.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10.&lt;/strong&gt; Repeat the process for new entities.
Make sure to use the same PartitionKey but a unique rowkey. Also be sure to use true or false for the oncall field.&lt;/p&gt;
&lt;p&gt;After a couple of entries, it should look as follows.
&lt;img src=&#34;on-call-table-entries.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s it. You&amp;rsquo;ve taken your first steps towards building a basic on-call roster. This will help us identify who to initially alert when an incident occurs.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This example roster tracks only the &amp;ldquo;&lt;strong&gt;Primary Responder&lt;/strong&gt;&amp;rdquo; (i.e. &lt;code&gt;oncall=true or false&lt;/code&gt;). It doesn&amp;rsquo;t include any alternative contact information. Nor does it identify what rotations someone is associated with.
&lt;br /&gt;&lt;br /&gt;
Try expanding your roster to contain more of the roles previously discussed.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Next, we will take a look at 
&lt;a href=&#34;/post/establishing-oncall-rotations/&#34;&gt;Establishing On-call Rotations&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Breaking Down the Components of a Post-incident Review</title>
      <link>/post/breaking-down-the-components-of-a-post-incident-review/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/breaking-down-the-components-of-a-post-incident-review/</guid>
      <description>&lt;p&gt;You now know what a post-incident review is, its role in the incident response
process, and when it should be conducted. In this unit, you’ll dive a little
deeper into the details of what makes a post-incident review most effective.&lt;/p&gt;
&lt;p&gt;Because incidents differ, the exact makeup of post-incident reviews can be
different, too. But there are some common characteristics and components of a
good review that can provide you with a solid foundation for carrying out the
process.&lt;/p&gt;
&lt;h2 id=&#34;what-its-not&#34;&gt;What it’s not&lt;/h2&gt;
&lt;p&gt;Before you can understand the characteristics that make for a good post-incident
review, you should consider what it’s &lt;em&gt;not.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;It’s not a document or report.&lt;/strong&gt; It’s easy to think of a “review” as a
written summary, and indeed, a summary report often follows a post-incident
review. However, these are two different and distinct parts of the Analysis
phase of the incident response lifecycle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;It’s not a determination of causality.&lt;/strong&gt; Your review will look at the
factors that contributed to the failure, but the purpose isn’t to pinpoint a
culprit. It’s to think about and share information about all aspects of the
incident in order to learn and improve.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;It’s not a list of action items.&lt;/strong&gt; You may end up with such a list as a
result of what you learn in the review, but this isn’t the focus. If you
don’t come away with a stepwise punch list but you do know more about your
systems than before, the review was successful.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The incident review is, more than anything, a &lt;em&gt;conversation.&lt;/em&gt; It’s a defined
space within which your team can review what they knew at the time and what they
know now, and explore and better understand how the parts of the system –
including the human parts – do or don’t work together in response to problems.&lt;/p&gt;
&lt;h2 id=&#34;characteristics-and-components&#34;&gt;Characteristics and components&lt;/h2&gt;
&lt;p&gt;A good incident review is, first and foremost, &lt;em&gt;blameless.&lt;/em&gt; Although you need to
examine how the human parts of the system interacted with it, you don’t do this
in order to label anyone “at fault.” The focus should be on the failures of the
technology and the process, not of the people.&lt;/p&gt;
&lt;p&gt;Frame your questions to reflect this:&lt;/p&gt;
&lt;p&gt;“What was the deficit in your monitoring that failed to give the person at the
keyboard the necessary context to make the right decision?”&lt;/p&gt;
&lt;p&gt;“Why was there a &lt;strong&gt;delete the entire database&lt;/strong&gt; option in the tool that didn’t ask
for confirmation?”&lt;/p&gt;
&lt;p&gt;When things go wrong, it can be tempting to point fingers. However, you must
remember this key point: &lt;em&gt;You can’t fire your way to reliability.&lt;/em&gt; Shaming and
blaming and an investigation that’s aimed at finding and firing the person who
is “responsible” won’t lead to more reliable systems. Instead, it will lead to
an inexperienced operations team and personnel who are afraid to act.&lt;/p&gt;
&lt;p&gt;Approach the review as a search for knowledge and context, not a hunt for who
did what and a reaction to that.&lt;/p&gt;
&lt;p&gt;Although the review is about the failures of the technology, it’s not a
technical process as much as it is a people process. Talk – and more important,
listen – to the people who were involved in the incident. Keep an open mind.
Different people have different perspectives and not everyone will agree, and
that mix of perspectives is invaluable to the learning process.&lt;/p&gt;
&lt;p&gt;A post-incident review is an honest inquiry. As such, it embraces these key
components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Discussion&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discourse&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dissent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Discovery&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These “4 Ds” create a framework on which you can build a post-incident learning
review that can result in more reliable systems and more productive teams that
work together.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/running-a-post-incident-review/&#34;&gt;Running a Post-incident Review&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Defining Alerts</title>
      <link>/post/defining-alerts/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/defining-alerts/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&amp;quot;An alert is something which requires a human to perform an action.&amp;rdquo; - Pagerduty 
&lt;a href=&#34;https://response.pagerduty.com/oncall/alerting_principles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Alerting Principles&amp;rdquo;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To understand why alerting can create a problem, you need to think about the purpose of alerts and how they differ from other monitoring components.&lt;/p&gt;
&lt;p&gt;Actionable alerts are &lt;em&gt;not&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Logs.&lt;/strong&gt; Alerts are not records of events; that’s the role of logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Notifications.&lt;/strong&gt; Alerts are not intended to announce non-critical
occurrences such as the completion of a software build.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Heartbeats.&lt;/strong&gt; Alerts shouldn’t be used to document failure of a heartbeat
signal periodically sent between two systems at regular intervals.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actionable alerts are used for situations in which you need a human to
investigate and intervene to remediate the problem. Alerts should be
communications that something exceptional or unexpected has happened that
requires someone’s attention.&lt;/p&gt;
&lt;p&gt;A lot of thought should be put in to how alerts are delivered and when it is necessary. 
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/alerts-overview/?wt.mc_id=oncalllife-blog-jahand&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;More on how to configure alerts in Azure can be found here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If the event is something that the system can handle through automated
processes, such as scaling resources within a preset limit, an alert is not
necessary. A simple line in a log should suffice.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/understanding-actionable-alerts&#34;&gt;Understanding Actionable Alerts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Defining Incidents</title>
      <link>/post/defining-incidents/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/defining-incidents/</guid>
      <description>&lt;p&gt;If you search online for &amp;ldquo;Incident Response&amp;rdquo; a majority of what you&amp;rsquo;ll find is information related to security threats and breaches. What doesn&amp;rsquo;t show up in the results is stuff about how to properly respond to threats related to something else entirely.&lt;/p&gt;
&lt;p&gt;How should a business respond to technical challenges and failures as they come up? The ones that affect reliability concerns such as availability, latency, correctness, and others. What happens when service level expectations are breached and it&amp;rsquo;s time for a human to get involved?&lt;/p&gt;
&lt;p&gt;Services such as VictorOps, PagerDuty, and others provide &amp;ldquo;on-call&amp;rdquo; solutions as well as documentation and best practices regarding this type of incident management. Service Now has opinions as well but the language is aimed more for those who follow ITSM guidance regarding service management. Ticketing with a tiered support structure doesn&amp;rsquo;t provide the fasted path to uptime for many companies however.&lt;/p&gt;
&lt;p&gt;In the devops and web operations space, the idea of anyone but the engineers building the system responding to customer impacting problems is completely unacceptable. Irresponsible even. Time is of the essence and those who helped build the applications and underlying infrastructure are the best suited to maintain it&amp;rsquo;s health and upgrades in a production environment.&lt;/p&gt;
&lt;p&gt;Exactly when an engineer should be expected to take action is why we need to define what we mean by an incident.&lt;/p&gt;
&lt;p&gt;We can all agree that an incident is a “&lt;strong&gt;service disruption&lt;/strong&gt;” - something that is affecting our user&amp;rsquo;s ability to use the services they have come to rely on.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s a given. However, there are other things about incidents that are often overlooked or never considered. For example incidents are commonly subjective, feared, and unexpected&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;from-microsofts-icm-documentation&#34;&gt;From Microsoft&amp;rsquo;s IcM Documentation&lt;/h2&gt;
&lt;h3 id=&#34;what-is-an-incident&#34;&gt;What is an incident?&lt;/h3&gt;
&lt;p&gt;An incident is any unplanned interruption or degradation of a product or service that is causing customer impact. For example, a bad HTTP request, slow connection, security vulnerability, or customer-reported error message could constitute an incident. Every service across Microsoft has a different definition of what an incident is and when one should be triggered.&lt;/p&gt;
&lt;p&gt;Sometimes, an incident can be severe enough to affect many different services and customers. For example, a datacenter power failure may impact dozens of Microsoft products. Severe incidents with broad impact are called outages.&lt;/p&gt;
&lt;p&gt;Typically any customer impacting incident must be mitigated as soon as possible to minimize the customer impact. Organizations track Time-To-Mitigate (TTM) metrics for their services. For example: In Azure, TTM must be &amp;lt;= 30mins for any customer impacting incident.&lt;/p&gt;
&lt;h3 id=&#34;what-is-incident-management&#34;&gt;What is incident management?&lt;/h3&gt;
&lt;p&gt;Incident Management is the process of detecting a live-site problem with a service, creating an incident, determining the cause, restoring the service to full operation, and capturing learnings to prevent it from happening again.&lt;/p&gt;
&lt;h3 id=&#34;what-is-icm&#34;&gt;What is IcM?&lt;/h3&gt;
&lt;p&gt;IcM is the one incident management system for all Microsoft services. IcM provides tools for managing live site and on call rotations. IcM runs around the clock to keep services working across the world. Incident Types supported are &amp;ldquo;Livesite Incident&amp;rdquo;, &amp;ldquo;Deployment Incident&amp;rdquo; and &amp;ldquo;Customer Reported Incidents&amp;rdquo;. No additional types will be supported.&lt;/p&gt;
&lt;h3 id=&#34;what-icm-is-not&#34;&gt;What IcM is not?&lt;/h3&gt;
&lt;p&gt;IcM is not intended to be a ticketing solution. IcM was designed for incidents that must be mitigated within minutes to minimize the customer impact. Here are some differences:&lt;/p&gt;
&lt;p&gt;In a ticketing solution, a ticket can take &amp;lsquo;n&amp;rsquo; days to resolve. In IcM, incidents need to be resolved as soon as possible to minimize customer impact.&lt;/p&gt;
&lt;p&gt;In a ticketing solution, teams might want to pause or have a count down timer for tickets. In IcM, this will not be supported because the incident has to be resolved in minutes.
In a ticketing solution, teams might want to customize the workflows. In IcM, incident workflow is fixed: Create -&amp;gt; Acknowledge -&amp;gt; Mitigate -&amp;gt; Resolve.&lt;/p&gt;
&lt;p&gt;In a ticketing solution, teams might want different &amp;lsquo;Types&amp;rsquo; and &amp;lsquo;Sub-Types&amp;rsquo;. In IcM, only types that will be supported are &amp;ldquo;Livesite Incident&amp;rdquo;, &amp;ldquo;Deployment Incident&amp;rdquo; and &amp;ldquo;Customer Reported Incidents&amp;rdquo;. This is to ensure that Service teams are focused on addressing the customer impacting incidents as soon as possible.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/exploring-subjectivity-of-incidents/&#34;&gt;Exploring Subjectivity of Incidents&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Defining Site Reliability Engineering</title>
      <link>/post/defining-site-reliability-engineering/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/defining-site-reliability-engineering/</guid>
      <description>&lt;p&gt;Site Reliability Engineering is an engineering discipline devoted to helping
organizations sustainably achieve the appropriate level of reliability in their
systems, services, and products.&lt;/p&gt;
&lt;p&gt;The key concepts to take away from this definition are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reliability.&lt;/strong&gt; You learned in the introductory module that there are
multiple aspects to reliability and later in this module, you’ll examine
each in more detail. You also learned about the importance of reliability –
why it matters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sustainability.&lt;/strong&gt; In this context, “sustainable” refers to the role of
people in creating a sustainable operations practice. Reliable systems,
services, products are built by people. It is crucial to the concept of SRE
to implement an operations practice that is sustainable over time, so that
people are able to bring their best to the job.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Appropriateness.&lt;/strong&gt; It’s important to understand that 100% reliability
isn’t often possible, especially in today’s complex systems with
dependencies on other systems. 100% reliability means zero down time, which
also means no opportunity to make any changes or improvements that could
create some down time. Instead of striving for a goal of absolute
reliability, determine the appropriate level of reliability for a particular
application or service.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The role of a site reliability engineer bridges the span between operations and
development but also goes beyond DevOps, and the SRE philosophy is the basis of
a new and more efficient and effective approach to building and operating
reliable systems and applications.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Establishing Communication Channels</title>
      <link>/post/establishing-communications-channel/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/establishing-communications-channel/</guid>
      <description>&lt;p&gt;To address some of the challenges around how we communicate we also want to find a way to create a unique channel or space for engineers to discuss the details of the incident - a “conversation bridge” in our persistent group chat tool -which for Tailwind Traders is Microsoft Teams.&lt;/p&gt;
&lt;p&gt;We want a channel that is unique to the incident only. We do not want conversations about other engineering efforts.We don’t want conversations about what people are doing for lunch. We ONLY want conversations related to the incident. Because then we can take that text (or data) and analyze later in a Post-incident review.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/understanding-why-we-learn-from-incidents/&#34;&gt;Understanding Why We Learn From Incidents&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Establishing On-call Roles</title>
      <link>/post/establishing-oncall-roles/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/establishing-oncall-roles/</guid>
      <description>&lt;p&gt;Creating a repeatable response plan means establishing who does what when something goes wrong. We don&amp;rsquo;t want there to be any question around who is supposed to be doing what.&lt;/p&gt;
&lt;p&gt;Because of this, it is important to establish roles and the associated expectations. This isn&amp;rsquo;t a separation of duties exercise. In fact, we want to encourage less of that. It is however, a way of establishing better coordination and communication. It prevents people from stepping on each others toes while enabling cross-collaboration amongst not only on-call rosters, but an entire organization.&lt;/p&gt;
&lt;p&gt;The first role we need to talk about is the &lt;strong&gt;Primary Responder&lt;/strong&gt; – the Primary “On-call” engineer.&lt;/p&gt;
&lt;p&gt;This person is expected to acknowledge their awareness of an incident once the alert has been received.&lt;/p&gt;
&lt;p&gt;Then we have the &lt;strong&gt;secondary responder&lt;/strong&gt; – who is there as back up -Another engineer who can step in if the primary responder is unavailable or unreachable. Or if they just need another pair of eyes.&lt;/p&gt;
&lt;p&gt;Another key role to identify, in many cases, is the &lt;strong&gt;incident commander&lt;/strong&gt;. An incident commander can be extremely helpful when you have got a large-scale outage that effects a lot of different components or requires coordination across many teams and different systems. They are great for making sure that engineers stay focused and they are working on their own remediation efforts&amp;hellip; Ensuring people are not stepping on each other or undoing each other&amp;rsquo;s work.  It is good to have a central person who can track what is going on and who is doing what.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Communication Coordinator&lt;/strong&gt; is meant to be the person working in conjunction with the incident commander to share more information beyond those who are in the firefight actively working to recover from the incident itself. That could be customers. It could be the sales and marketing teams. Maybe your customer support. There are many people within an organization who need to be made aware of what’s taking place and the status around how things are progressing. It&amp;rsquo;s always good to put someone in charge of managing that communication and making sure that other stakeholders are aware of what is happening and what’s being done.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;scribe&lt;/strong&gt;’s role is to document the conversation in as much detail as possible. Teams commonly use phone bridges, conference calls, or video chat to get everyone together and try to understand what is going on, which can certainly help create space for the conversation. However, it is difficult for us to go through and understand in detail what the engineers were saying and doing unless it is transcribed. As a result, a scribe is that person who can help us document as much as possible to review later. What were people saying, doing, feeling, and even experiencing?  It is all data to be analyzed – but only if we capture it.&lt;/p&gt;
&lt;p&gt;It’s quite common within on-call rosters to identify &lt;strong&gt;subject matter experts&lt;/strong&gt;, so that early responders know who to escalate too quickly. These people should not be on call all the time, of course, but we do want to be able to identify who is our database expert. Who is our front-end expert? Who are the people that we can reach out to if our primary and secondary responders are not able to diagnose and resolve the issue themselves?&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a closer look at each of these roles to better understand their place within our incident response efforts.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/identifying-the-primary-responder/&#34;&gt;Identifying the Primary Responder&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Establishing On-call Rosters</title>
      <link>/post/establishing-oncall-rosters/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/establishing-oncall-rosters/</guid>
      <description>&lt;p&gt;Rosters establish a framework around who is on-call at any given point. A roster, or team, is made up of multiple engineers. Rosters can also contain multiple rotations. I&amp;rsquo;m testing out how to edit a page.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/creating-an-oncall-roster-using-azure-table-storage/&#34;&gt;Creating an on-call roster using Azure Table Storage&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Establishing On-call Rotations</title>
      <link>/post/establishing-oncall-rotations/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/establishing-oncall-rotations/</guid>
      <description>&lt;p&gt;People shouldn&amp;rsquo;t have to be &lt;em&gt;on-call&lt;/em&gt; for long periods of time. It&amp;rsquo;s detrimental to their health and therefore the systems they create and look after.&lt;/p&gt;
&lt;p&gt;In order to make sure people aren&amp;rsquo;t expected to respond to problems 24-hours a day, indefinitely, we use rotations. Also referred to as scheduled shifts. That way people can take turns.&lt;/p&gt;
&lt;p&gt;Being on-call requires a heavy cognitive task which then negatively impacts many aspects of a person&amp;rsquo;s life. Shifts allow engineers to take “on-call” responsibility for their own specific recurring rotation and share the load in a way that keeps the human element a priority.&lt;/p&gt;
&lt;p&gt;Site Reliability Engineering is an engineering discipline devoted to helping an organization &lt;strong&gt;sustainably&lt;/strong&gt; achieve the appropriate level of reliability in their systems, services, and products. Long periods of on-call responsibilities is &lt;strong&gt;not&lt;/strong&gt; sustainable.&lt;/p&gt;
&lt;p&gt;When creating shifts there are a number of common approaches.&lt;/p&gt;
&lt;h2 id=&#34;24-x-7&#34;&gt;24 x 7&lt;/h2&gt;
&lt;p&gt;The majority of rotations used by teams are known as 27 x 7 shifts where engineers will be “on-call” for several days in a row. However, most “Elite/High performers” would agree that rotations longer than 3 or 4 days are detrimental to the overall health of engineering staff and therefore the entire system.&lt;/p&gt;
&lt;h2 id=&#34;follow-the-sun&#34;&gt;Follow the Sun&lt;/h2&gt;
&lt;p&gt;Follow the sun shifts are nice for distributed teams. These allow for engineers to schedule their “on-call” shifts only during their normal working office hours. As they end their day and go home, engineers in a different time zone can take over.&lt;/p&gt;
&lt;p&gt;And of course, there are many ways to customize shifts, especially for weekends when engineers need more flexibility. Engineers should be able to hand off the role to someone when personal conflicts arise.&lt;/p&gt;
&lt;p&gt;Once roles, rosters, and rotations have been determined and put in place, we can now focus our attion on methods of 
&lt;a href=&#34;/post/tracking-incident-details/&#34;&gt;Tracking Incident Details&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Identifying the Communication Coordinator</title>
      <link>/post/identifying-the-communication-coordinator/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/identifying-the-communication-coordinator/</guid>
      <description>&lt;p&gt;The Communication Coordinator is meant to be the person working in conjunction with the incident commander to share more information beyond those who are in the firefight actively working to recover from the incident itself. That could be customers. It could be the sales and marketing teams. Maybe your customer support. There are many people within an organization who need to be made aware of what’s taking place and the status around how things are progressing. It&amp;rsquo;s always good to put someone in charge of managing that communication and making sure that other stakeholders are aware of what is happening and what’s being done.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/identifying-the-scribe/&#34;&gt;Identifying The Scribe&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Identifying the Incident Analysis Phase</title>
      <link>/post/identifying-the-incident-analysis-phase/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/identifying-the-incident-analysis-phase/</guid>
      <description>&lt;p&gt;The post-incident review is where the idea of incidents begin to shift from things that are feared and avoided to things that can provide valuable information to a team and business.&lt;/p&gt;
&lt;p&gt;Rarely will you find a business today that doesn&amp;rsquo;t heavily rely on digital services to earn and keep customers. There are going to be problems along the way. Not only that, but customers expect improvements, technology changes, competitors get smarter. There are fewer and fewer industries that can maintain the status quo and continue to exist, let alone prosper.&lt;/p&gt;
&lt;p&gt;The analysis phase allows for an honest and open retrospective discussion about what took place. We as an organization want to understand the realities of the scenario from an objective perspective.&lt;/p&gt;
&lt;p&gt;Exactly how you conduct the exercises will vary but the focus of the conversation is on what and how things happened rather than who and why.&lt;/p&gt;
&lt;p&gt;By identifying the incident timeline as well as the specific highlights, people can identify the beginning and end of each phase, including the conversations that took place.&lt;/p&gt;
&lt;p&gt;This helps isolate specific areas of improvements such as moving away from using email distribution lists as the default channel and method of delivering actionable alerts. In discussions about the detection phase, it seemed clear to everyone that the problem could have been solved sooner had they known about it sooner. Sometimes even small changes can have a huge impact on improving the overall time to recover.&lt;/p&gt;
&lt;p&gt;Regardless of how businesses choose to perform their post-incident review, they should take place no more than 36-48 hours after the incident has concluded.&lt;/p&gt;
&lt;p&gt;We are looking to collect as much objective data as well as testimonial from a diverse set of perspectives. It&amp;rsquo;s difficult to remember what took place in much detail after a couple of days.&lt;/p&gt;
&lt;p&gt;If possible, the exercise should be facilitated by someone that was not involved in the incident. Someone who can remove themselves from the timeline of events and perspectives of what took place. Objective data is often easier to obtain when someone else asks the questions and encourages an honest conversation.&lt;/p&gt;
&lt;p&gt;The point of a post-incident review isn&amp;rsquo;t to end up with a document or artifact that the meeting took place. It&amp;rsquo;s not an exploration on what definitively caused the issue in the first place.&lt;/p&gt;
&lt;p&gt;Our systems are always changing. That&amp;rsquo;s just where we are today. Businesses that are providing some kind of service to their customers where technology is involved are required to make constant changes. It doesn&amp;rsquo;t matter if it&amp;rsquo;s in the cloud, data center, or closet, servers need improvements and replacements. Operating systems need patches and upgrades. Applications need to be updated and restarted. Databases and logs are changing and growing. Networks are coming and going. There&amp;rsquo;s a lot going on and it&amp;rsquo;s often difficult to put our thumb on exactly what&amp;rsquo;s causing what.&lt;/p&gt;
&lt;p&gt;The good news is, it&amp;rsquo;s ok.&lt;/p&gt;
&lt;p&gt;Part of the advantage of examining incidents in phases means that regardless to the problems we experience in the future, we know that we can detect a problem, get the right people involved, and recover services faster than before. We are prepared for the infinite world of possibilities we like to call the &amp;ldquo;unknown unknowns&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This takes us to our final phase of the incident lifecycle, readiness.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/identifying-the-incident-readiness-phase&#34;&gt;Identifying the Readiness Phase of an Incident&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Identifying the Incident Commander</title>
      <link>/post/identifying-the-incident-commander/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/identifying-the-incident-commander/</guid>
      <description>&lt;p&gt;Another key role to identify, in many cases, is the incident commander. An incident commander can be extremely helpful when you have got a large-scale outage that effects a lot of different components or requires coordination across many teams and different systems. They are great for making sure that engineers stay focused and they are working on their own remediation efforts&amp;hellip; Ensuring people are not stepping on each other or undoing each other&amp;rsquo;s work.  It is good to have a central person who can track what is going on and who is doing what.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;/post/identifying-the-communication-coordinator/&#34;&gt;Identifying the Communication Coordinator&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sending Actionable Alerts</title>
      <link>/post/sending-actionable-alerts/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/sending-actionable-alerts/</guid>
      <description>&lt;p&gt;Alerts play an important role in your reliability monitoring strategy, but in
order to be helpful, they must be properly constructed for situations that
warrant immediate human attention, and they should be devised with simplicity,
scope, and context in mind.&lt;/p&gt;
&lt;p&gt;Preferences on how alerts are delivered can be designed using 
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/action-groups/?wt.mc_id=oncalllife-blog-jahand&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Action Groups&lt;/a&gt; in Azure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://docs.microsoft.com/en-us/azure/azure-monitor/platform/media/action-groups/action-group-define.png&#34; alt=&#34;Action Group&#34;&gt;&lt;/p&gt;
&lt;p&gt;You have learned how to monitor and interact with indicators of
the reliability of your systems and create reliability goals, but there is also
an important way by which reliability interacts with you. That’s through Azure
Monitor’s log alerts feature.&lt;/p&gt;
&lt;p&gt;It’s easy to create log alerts using Azure Monitor where the signal is a log
query in Log Analytics or Application Insights. However, there is a pitfall that
you’ll want to avoid, to prevent derailing all the effort you have put into
bringing SLIs and SLOs into your organization.&lt;/p&gt;
&lt;p&gt;To understand this potential pitfall, review the definition of SRE:&lt;/p&gt;
&lt;p&gt;“Site Reliability Engineering is an engineering discipline devoted to helping
organizations &lt;strong&gt;sustainably&lt;/strong&gt; achieve the appropriate level of reliability in
their systems, services, and products.”&lt;/p&gt;
&lt;p&gt;Alerts are designed to notify you when there is a problem with your systems.
However, when alerts are improperly configured, this can undermine your goal of
sustainability. Log alert rules are stateless; they work only on the logic that
you build into the query and they send an alert whenever the alert condition is
“true.” Thus, it’s important to put some thoughts into constructing your alerts.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/defining-alerts&#34;&gt;Defining Alerts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Actionable Alerts</title>
      <link>/post/understanding-actionable-alerts/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/understanding-actionable-alerts/</guid>
      <description>&lt;p&gt;To create effective actionable alerts, you must understand their components and
characteristics. Actionable alerts have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Simplicity&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scope&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Context&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Simplicity is self-explanatory: make your alerts easy for you and others to
understand, even if you’re reading them after being awakened at 2:00 a.m. Scope
and context should be included in the content of the alert.&lt;/p&gt;
&lt;p&gt;Let’s look at some elements that an actionable alert should always include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The source:&lt;/strong&gt; information about where the alert is coming from. Many
organizations have multiple monitoring systems in use at any one time and a
large number of interconnected systems. It can save someone a tremendous
amount of time if the alert says &amp;ldquo;This alert for payroll system thx-1138 is
coming from Azure monitor subscription prod.&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt; information about what expectation has been violated. For
example, &amp;ldquo;This server has been returning an error 30% of the time when it
should have been returning errors less than 1% of the time.&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Impact and scope:&lt;/strong&gt; information about the effect or impact the situation
has had or potentially will have and the scope of that impact (ideally,
stated from the customer’s point of view).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Recommended action:&lt;/strong&gt; if possible, the alert should include what the
person responding should do next, even if that is a pointer to a
troubleshooting guide or some other documentation to find help in diagnosing
and remediating this problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Including such helpful context will make operations practices around monitoring
more sustainable and make responding to alerts easier.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;/post/defining-incidents&#34;&gt;Defining Incidents&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
